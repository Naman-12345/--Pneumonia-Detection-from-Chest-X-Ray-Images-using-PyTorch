{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRp0zY0gH-_l",
        "outputId": "66296fac-a3d1-4394-876c-17e1191aba66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chest-xray-pneumonia.zip to ./chest-xray-pneumonia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.29G/2.29G [00:19<00:00, 124MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets --upgrade --quiet\n",
        "import opendatasets as od\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "dataset_url='https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia'\n",
        "od.download(dataset_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_directory = '/content/chest-xray-pneumonia'\n",
        "os.makedirs(dataset_directory, exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "class ChestDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.dataset = ImageFolder(root=data_path, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        return image, label\n",
        "\n",
        "train_data_path = os.path.join(dataset_directory, 'chest_xray/train')\n",
        "val_data_path = os.path.join(dataset_directory, 'chest_xray/val')\n",
        "test_data_path = os.path.join(dataset_directory, 'chest_xray/test')\n",
        "\n",
        "train_dataset = ChestDataset(train_data_path, transform=transform)\n",
        "val_dataset = ChestDataset(val_data_path, transform=transform)\n",
        "test_dataset = ChestDataset(test_data_path, transform=transform)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "class ChestCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChestCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(16 * 128 * 128, 64)  # Adjust the input size depending on your image size\n",
        "        self.fc2 = nn.Linear(64, 2)  # 2 output classes: Normal and Pneumonia\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 128 * 128)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = ChestCNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 11: Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Step 12: Evaluation on validation set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Step 13: Evaluation on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-akuv5nIMOi",
        "outputId": "b252ed01-000e-4162-9dba-4eafe49009a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Loss: 0.1390\n",
            "Epoch [2/10] - Loss: 0.0891\n",
            "Epoch [3/10] - Loss: 0.0518\n",
            "Epoch [4/10] - Loss: 0.1139\n",
            "Epoch [5/10] - Loss: 0.0693\n",
            "Epoch [6/10] - Loss: 0.0188\n",
            "Epoch [7/10] - Loss: 0.0449\n",
            "Epoch [8/10] - Loss: 0.0093\n",
            "Epoch [9/10] - Loss: 0.0091\n",
            "Epoch [10/10] - Loss: 0.0034\n",
            "Validation Accuracy: 93.75%\n",
            "Test Accuracy: 74.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2DkvIIN6KACM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}